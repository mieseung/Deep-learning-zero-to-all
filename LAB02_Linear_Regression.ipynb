{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LAB02 Linear Regression.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOg5uMEaoVuzt+NH+ufUExn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "cxT9r__2UQm8"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtGBhxpkUfiC"
      },
      "source": [
        "공부한 시간과 점수의 데이터를 사용하여, 둘의 상관관계를 평가해보려고 한다.\n",
        "\n",
        "- 보통 입력은 `x`, 출력은 `y` 를 사용해서 표현함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3lkBM0EUeve"
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[2], [4], [6]])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69_7uxyrU8Fd"
      },
      "source": [
        "Hypothesis : y = Wx + b\n",
        "- W : weight, b : bias\n",
        "- W와 b를 학습을 통해 파악하는 것이 우리의 목적이기 때문에 초기에는 모두 0으로 초기화해줌.\n",
        "- `requires_grad = True` 학습할 것이라고 명시함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qay3yQNbVP7u"
      },
      "source": [
        "W = torch.zeros(1, requires_grad = True)\n",
        "b = torch.zeros(1, requires_grad=True)\n",
        "hypothesis = x_train * W + b"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YmK9N1f1Vk0X"
      },
      "source": [
        "# Compute loss\n",
        "<b> Mean Squred Error (MSE) <b>를 사용해서 계산함.\n",
        "- `torch.mean()` 함수를 통해 쉽게 계산할 수 있음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S912fU2jVxWp",
        "outputId": "d3af567a-64c5-4025-8e4d-44d96aa810e3"
      },
      "source": [
        "cost = torch.mean((hypothesis - y_train)**2)\n",
        "print(cost)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(18.6667, grad_fn=<MeanBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPiLQC3rV8Vy"
      },
      "source": [
        "# Grandient Descent\n",
        "\n",
        "계산한 loss를 바탕으로 모델을 개선시킴.\n",
        "- `torch.optim` 라이브러리를 사용하고, 학습할 tensor(모수)를 [W, b]로, lr은 learning rate로 지정해줌.\n",
        "\n",
        "### 항상 붙어다니는 3줄\n",
        "- `zero_grad()`로 gradient 초기화\n",
        "- `backward()`로 `gradient 계산\n",
        "- `step()`으로 계사\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zmxmFkUkWDdz"
      },
      "source": [
        "optimizer = torch.optim.SGD([W, b], lr = 0.01) # SGD : loss를 최소화하는 방식\n",
        "\n",
        "nb_epochs = 1000\n",
        "for epoch in range(1, nb_epochs+1):\n",
        "  hypothesis = x_train * W +b\n",
        "  cost = torch.mean((hypothesis-y_train)**2)\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VjwmQ8JXGu_"
      },
      "source": [
        "### 한 번만 수행\n",
        "1. 데이터 정의\n",
        "2. hypothesis 초기화\n",
        "3. optimizer 정의\n",
        "\n",
        "### epoch만큼 반복 수행\n",
        "1. hypothesis 예측\n",
        "2. cost 계산\n",
        "3. optimizer로 학습"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-03 Deeper Look at GD.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNEeXnhHNV1hRzQTM1pHw//"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aR3E2FWxfp0Q"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E8W5K5sfzrY"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bf11jYaMgCLH"
      },
      "source": [
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGm6sJmegKUI"
      },
      "source": [
        "`x_train`과 `y_train`이 동일하므로 `W = 1`일 때 정확한 모델임. \n",
        "\n",
        "**cost function**이 작을수록 좋은 모델이기 때문에, 이를 최소화하는 W를 찾아야함. \n",
        "\n",
        "Linear regression에서는 보통 MSE를 사용함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7B1ChbKygp92"
      },
      "source": [
        "### Gradient Descent\n",
        "-cost function을 최소화하려면 기울기가 음수일 때에는 W가 더 커져야하고, 기울기가 양수이면 W가 더 작아져야함.\n",
        "-기울기가 가파를 수록 cost가 큰 것이므로 W를 크게, 완만할수록 W를 작게 바빠야할 것임.\n",
        "-여기서의 기울기를 gradient라고 하고, 이 기울기는 cost function을 미분한 값임."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "zcGcY1Vkge77",
        "outputId": "feb9ce08-8748-4fd5-9780-3dff82c3970b"
      },
      "source": [
        "# cost function을 W에 대해 미분한 결과를 통해 gradient를 구함.  \n",
        "gradient = 2 * torch.mean((W * x_train - y_train)*x_train)\n",
        "lr = 0.1\n",
        "W -= lr*gradient"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-444efda70b3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# cost function을 W에 대해 미분한 결과를 통해 gradient를 구함.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mgradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T78NG1FhhvQp",
        "outputId": "18de3020-c7d8-46a3-ec9e-99d28c4e2d04"
      },
      "source": [
        "# data\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "\n",
        "# model initialization\n",
        "W = torch.zeros(1)\n",
        "\n",
        "# learning rate setting\n",
        "lr = 0.1\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # compute H(x)\n",
        "  hypothesis = x_train * W\n",
        "\n",
        "  # compute cost gradient\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "  gradient = torch.sum((W * x_train - y_train) * x_train)\n",
        "\n",
        "  print('Epoch {:4d} / {} W: {:.3f}, Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, W.item(), cost.item()\n",
        "  ))\n",
        "\n",
        "  # compute H(x) with cost gradient\n",
        "  W -= lr * gradient"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0 / 15 W: 0.000, Cost: 4.666667\n",
            "Epoch    1 / 15 W: 1.400, Cost: 0.746666\n",
            "Epoch    2 / 15 W: 0.840, Cost: 0.119467\n",
            "Epoch    3 / 15 W: 1.064, Cost: 0.019115\n",
            "Epoch    4 / 15 W: 0.974, Cost: 0.003058\n",
            "Epoch    5 / 15 W: 1.010, Cost: 0.000489\n",
            "Epoch    6 / 15 W: 0.996, Cost: 0.000078\n",
            "Epoch    7 / 15 W: 1.002, Cost: 0.000013\n",
            "Epoch    8 / 15 W: 0.999, Cost: 0.000002\n",
            "Epoch    9 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   10 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   11 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   12 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   13 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   14 / 15 W: 1.000, Cost: 0.000000\n",
            "Epoch   15 / 15 W: 1.000, Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ37hH-Fi0iB"
      },
      "source": [
        "### Gradient Descent with `torch.optim`\n",
        "\n",
        "`torch.optim`으로도 gradient descent를 할 수 있음.\n",
        "- 시작할 때 Optimizer를 정의\n",
        "- `optimizer.zero_grad()`로 gradient를 0으로 초기화\n",
        "- `cost.backward()`로 cost function을 미분해서 gradient를 계산\n",
        "- `optimizer.step()`으로 gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OuyeDZ5jL7m",
        "outputId": "53a9ea37-244c-4059-890d-17c8d8969c55"
      },
      "source": [
        "# data\n",
        "x_train = torch.FloatTensor([[1], [2], [3]])\n",
        "y_train = torch.FloatTensor([[1], [2], [3]])\n",
        "\n",
        "# model initialization\n",
        "W = torch.zeros(1, requires_grad=True) \n",
        "\n",
        "# optimizer setting\n",
        "optimizer = torch.optim.SGD([W], lr=0.15)\n",
        "\n",
        "nb_epochs = 10\n",
        "for epoch in range(nb_epochs + 1):\n",
        "\n",
        "  # compute H(x)\n",
        "  hypothesis = x_train * W\n",
        "\n",
        "  # compute cost gradient\n",
        "  cost = torch.mean((hypothesis - y_train)**2)\n",
        "\n",
        "  print('Epoch {:4d} / {} W: {:.3f}, Cost: {:.6f}'.format(\n",
        "      epoch, nb_epochs, W.item(), cost.item()\n",
        "  ))\n",
        "\n",
        "  # compute H(x) with cost gradient\n",
        "  optimizer.zero_grad()\n",
        "  cost.backward()\n",
        "  optimizer.step()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0 / 10 W: 0.000, Cost: 4.666667\n",
            "Epoch    1 / 10 W: 1.400, Cost: 0.746667\n",
            "Epoch    2 / 10 W: 0.840, Cost: 0.119467\n",
            "Epoch    3 / 10 W: 1.064, Cost: 0.019115\n",
            "Epoch    4 / 10 W: 0.974, Cost: 0.003058\n",
            "Epoch    5 / 10 W: 1.010, Cost: 0.000489\n",
            "Epoch    6 / 10 W: 0.996, Cost: 0.000078\n",
            "Epoch    7 / 10 W: 1.002, Cost: 0.000013\n",
            "Epoch    8 / 10 W: 0.999, Cost: 0.000002\n",
            "Epoch    9 / 10 W: 1.000, Cost: 0.000000\n",
            "Epoch   10 / 10 W: 1.000, Cost: 0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
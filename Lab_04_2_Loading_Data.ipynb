{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab-04-2 Loading Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMqDFBJwZzBKHwQr5kvL/i9"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6UWMEPEAomDg"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7JcjMlmpAIm"
      },
      "source": [
        "## Minibatch Gradient Descent\n",
        "전체 데이터를 minibatch로 균일하게 나눠서 학습하자.\n",
        "- 업데이트를 좀더 빠르게 할 수 있다.\n",
        "- 전체 데이터를 쓰지 않아서 잘못된 방향으로 업데이트할 수도 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlynaDfLpWGO"
      },
      "source": [
        "## PyTorch Dataset\n",
        "\n",
        "- `torch.utils.data.Dataset` 상속\n",
        "- `__len__()` : 이 데이터셋의 총 데이터 수\n",
        "- `__getitem__()` : 어떠한 인덱스 idx를 받았을 때, 그에 상응하는 입출력 데이터를 반환함."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-psbvI2pEeM"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "  def __init__(self):\n",
        "    self.x_data = [[73, 80, 75], \n",
        "                   [93, 88, 93],\n",
        "                   [89, 91, 90],\n",
        "                   [96, 98, 100],\n",
        "                   [73, 66, 70]]\n",
        "\n",
        "    self.y_data = [[152], [185], [180], [196], [142]]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "  \n",
        "  def __getitem__(self, idx):\n",
        "    x = torch.FloatTensor(self.x_data[idx])\n",
        "    y = torch.FloatTensor(self.y_data[idx])\n",
        "\n",
        "    return x, y\n",
        "\n",
        "dataset = CustomDataset()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkOGXfHeqRWf"
      },
      "source": [
        "Dataset을 만들었으면 pytorch에서 제공하는 DataLoader를 사용할 수 있음.\n",
        "- `batch_size = 2`\n",
        "\n",
        "  각 minibatch의 크기로, 통상적으로 2의 제곱수로 설정된다.\n",
        "- `shuffle = True`\n",
        "\n",
        "  Epoch마다 데이터셋을 섞어서 데이터가 학습되는 순서를 바꾼다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPJwo6UYpEmQ"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size = 2,\n",
        "    shuffle = True\n",
        ")\n",
        "\n",
        "\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuuwKz75q4lP"
      },
      "source": [
        "- `enumerate(dataloader)`\n",
        "\n",
        "  minibatch 인덱스와 데이터를 받음.\n",
        "\n",
        "- `len(dataloader)`\n",
        "\n",
        "  한 epoch당 minibatch의 개수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74FrjMelquIZ",
        "outputId": "89be59ee-22bc-4813-91f2-7cee3ce2f34a"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MultivariateLinearRegressionModel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.linear = nn.Linear(3, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.linear(x)\n",
        "\n",
        "model = MultivariateLinearRegressionModel()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 1e-5)\n",
        "\n",
        "nb_epochs = 20\n",
        "\n",
        "for epoch in range(nb_epochs+1):\n",
        "  for batch_idx, samples in enumerate(dataloader):\n",
        "    x_train, y_train = samples\n",
        "\n",
        "    # compute H(x)\n",
        "    prediction = model(x_train)\n",
        "\n",
        "    # compute cost\n",
        "    cost = F.mse_loss(prediction, y_train)\n",
        "\n",
        "    # compute H(x) with cost function\n",
        "    optimizer.zero_grad()\n",
        "    cost.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
        "        epoch, nb_epochs, batch_idx+1, len(dataloader), cost.item()\n",
        "    ))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch    0/20 Batch 1/3 Cost: 16937.949219\n",
            "Epoch    0/20 Batch 2/3 Cost: 2618.766113\n",
            "Epoch    0/20 Batch 3/3 Cost: 871.337402\n",
            "Epoch    1/20 Batch 1/3 Cost: 469.784546\n",
            "Epoch    1/20 Batch 2/3 Cost: 157.781311\n",
            "Epoch    1/20 Batch 3/3 Cost: 44.423763\n",
            "Epoch    2/20 Batch 1/3 Cost: 23.522087\n",
            "Epoch    2/20 Batch 2/3 Cost: 11.068324\n",
            "Epoch    2/20 Batch 3/3 Cost: 1.284993\n",
            "Epoch    3/20 Batch 1/3 Cost: 5.700742\n",
            "Epoch    3/20 Batch 2/3 Cost: 1.225294\n",
            "Epoch    3/20 Batch 3/3 Cost: 16.088623\n",
            "Epoch    4/20 Batch 1/3 Cost: 2.765476\n",
            "Epoch    4/20 Batch 2/3 Cost: 4.812294\n",
            "Epoch    4/20 Batch 3/3 Cost: 13.542346\n",
            "Epoch    5/20 Batch 1/3 Cost: 6.549115\n",
            "Epoch    5/20 Batch 2/3 Cost: 3.987715\n",
            "Epoch    5/20 Batch 3/3 Cost: 2.875637\n",
            "Epoch    6/20 Batch 1/3 Cost: 7.041916\n",
            "Epoch    6/20 Batch 2/3 Cost: 2.299312\n",
            "Epoch    6/20 Batch 3/3 Cost: 7.708638\n",
            "Epoch    7/20 Batch 1/3 Cost: 4.685853\n",
            "Epoch    7/20 Batch 2/3 Cost: 7.435233\n",
            "Epoch    7/20 Batch 3/3 Cost: 4.479963\n",
            "Epoch    8/20 Batch 1/3 Cost: 6.548425\n",
            "Epoch    8/20 Batch 2/3 Cost: 2.988237\n",
            "Epoch    8/20 Batch 3/3 Cost: 5.674523\n",
            "Epoch    9/20 Batch 1/3 Cost: 7.686752\n",
            "Epoch    9/20 Batch 2/3 Cost: 1.679163\n",
            "Epoch    9/20 Batch 3/3 Cost: 8.357919\n",
            "Epoch   10/20 Batch 1/3 Cost: 3.714224\n",
            "Epoch   10/20 Batch 2/3 Cost: 5.596579\n",
            "Epoch   10/20 Batch 3/3 Cost: 5.341589\n",
            "Epoch   11/20 Batch 1/3 Cost: 4.420811\n",
            "Epoch   11/20 Batch 2/3 Cost: 6.324098\n",
            "Epoch   11/20 Batch 3/3 Cost: 3.384239\n",
            "Epoch   12/20 Batch 1/3 Cost: 0.403520\n",
            "Epoch   12/20 Batch 2/3 Cost: 8.760241\n",
            "Epoch   12/20 Batch 3/3 Cost: 6.679499\n",
            "Epoch   13/20 Batch 1/3 Cost: 4.337534\n",
            "Epoch   13/20 Batch 2/3 Cost: 9.621898\n",
            "Epoch   13/20 Batch 3/3 Cost: 3.197142\n",
            "Epoch   14/20 Batch 1/3 Cost: 0.489227\n",
            "Epoch   14/20 Batch 2/3 Cost: 13.262660\n",
            "Epoch   14/20 Batch 3/3 Cost: 4.732497\n",
            "Epoch   15/20 Batch 1/3 Cost: 1.022258\n",
            "Epoch   15/20 Batch 2/3 Cost: 8.319889\n",
            "Epoch   15/20 Batch 3/3 Cost: 6.048180\n",
            "Epoch   16/20 Batch 1/3 Cost: 5.321831\n",
            "Epoch   16/20 Batch 2/3 Cost: 7.231026\n",
            "Epoch   16/20 Batch 3/3 Cost: 4.217478\n",
            "Epoch   17/20 Batch 1/3 Cost: 3.506405\n",
            "Epoch   17/20 Batch 2/3 Cost: 9.629215\n",
            "Epoch   17/20 Batch 3/3 Cost: 4.060715\n",
            "Epoch   18/20 Batch 1/3 Cost: 4.564441\n",
            "Epoch   18/20 Batch 2/3 Cost: 6.808957\n",
            "Epoch   18/20 Batch 3/3 Cost: 1.572472\n",
            "Epoch   19/20 Batch 1/3 Cost: 6.988225\n",
            "Epoch   19/20 Batch 2/3 Cost: 2.733185\n",
            "Epoch   19/20 Batch 3/3 Cost: 8.363919\n",
            "Epoch   20/20 Batch 1/3 Cost: 6.392580\n",
            "Epoch   20/20 Batch 2/3 Cost: 4.535537\n",
            "Epoch   20/20 Batch 3/3 Cost: 6.177655\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}